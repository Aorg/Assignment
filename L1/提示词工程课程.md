 ![1729033461435](image/提示词工程课程/1729033461435.png)

![img]()

# 前置知识：

内容来源：[Docs](https://aicarrier.feishu.cn/wiki/OWTqwyjEkiGJbCkxib5cGV8Wn1d "Docs")

### 模型设置

在使用提示词的时候，您会通过 API 或者网页版与大语言模型进行交互，将这些参数、设置调整到最佳程度会提高使用大语言模型时候的体验感和效果，下面就是一些常见的设置：

1. Temperature

temperature 参数值越小，模型就会返回越确定的一个结果。较高的 temperature 值会增加随机性，使得模型更可能选择不那么常见的选项，从而产生更多样化和创造性的输出。在实际应用时，如果是 QA，可以用比较小的 temperature，如果是文学作品、诗歌写作，可以用比较大的temperature。

1. Top_p

这是一种称为nucleus sampling的文本生成策略，它限制了模型在生成下一个词时考虑的候选词的数量。具体来说，Top_p参数决定了在生成时考虑的候选词的累积概率上限。例如，如果设置Top_p为0.9，那么只有累积概率最高的前10%的词会被考虑用于生成。

1. Max Length

这个参数指定了生成文本的最大长度，即模型在停止生成新词之前可以生成的最多字符数或词数。

1. Frequency Penalty

这个参数用于控制常见词和不常见词在生成过程中的相对概率。增加频率惩罚会降低常见词被选中的概率，从而鼓励模型生成更多样化的文本。

1. Presence Penalty

这个参数影响已经生成的词再次出现的概率。增加存在惩罚会减少这些词再次被选中的机会，有助于生成更多样化的文本，避免重复。

### 提示技术

* 少样本提示

从数据中抓取少数样本作为上下文提示

* 2.COT思维链

最早论文中提示中加入“think step by step”，“一步一步思考”

* 3思维树（ToT）

检索增强生成(RAG)

自动推理并使用工具(ART)

自动提示工程师

Active-Prompt

方向性刺激提示

Program-Aided

Language Models

ReAct框架

Reflexion

多模态思维链提示方法

基于图的提示

# 任务截图

尝试internlm2-chat-1_8b" +COT：

## 代码

```
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.core.llms import ChatMessage
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.huggingface import HuggingFaceLLM

embed_model = HuggingFaceEmbedding(
    model_name="/root/model/sentence-transformer"
)

Settings.embed_model = embed_model

llm = HuggingFaceLLM(
    model_name="/root/model/internlm2-chat-1_8b",
    tokenizer_name="/root/model/internlm2-chat-1_8b",
    model_kwargs={"trust_remote_code":True},
    tokenizer_kwargs={"trust_remote_code":True}
)
Settings.llm = llm
documents = SimpleDirectoryReader("/root/data/data").load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()
response = query_engine.query("xtuner支持哪些模型")
print("xtuner支持哪些模型",response)
print("================================提示工程==================================")
response = query_engine.query("xtuner支持哪些模型？一步一步慢慢来详细具体的回答，让我明白有哪些模型可以使用xtuner进行微调")
print("RAG+COT:",response)
```


## 没有提示和有提示的结果对比

蓝色框是有提示的结果
​​
![](https://i-blog.csdnimg.cn/direct/deaa725ea39f4620b4071aed4d23f527.png)![]()
